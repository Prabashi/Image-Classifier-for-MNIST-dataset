{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2O2HoIY2W1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBlDoHBe3pPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "648c4ade-cfe3-4b02-811c-8cf2df2829e2"
      },
      "source": [
        "# load data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5EcVxYe4Uph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "# Set input shape in the first layer\n",
        "# First convolutional layer with filter size (3,3) and 32 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer with filter size (3,3) and 64 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "#  Flatten to provide features to the classifier\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layer to interpret the features with 64 nodes\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# To handle overfitting\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output layer. Has 10 nodes for 0-9 outputs. Use a softmax activation to find probabilities and assign classes\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZuoQ805SpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt = SGD(lr=0.01, momentum=0.9) # Stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9\n",
        "# opt = 'adam'\n",
        "opt = 'rmsprop'\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj3qa5U2_y1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing of the images\n",
        "# Reshape dataset to have 4D vector with the number of channels of the input image as 1 (since image is grayscale)\n",
        "train_X = train_X.reshape((60000, 28, 28, 1))\n",
        "test_X = test_X.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize by rescaling pixel values from range [0, 255] to [0, 1] by 1st converting the value to float and then by dividing from max value\n",
        "train_X= train_X.astype('float32') / 255\n",
        "test_X= test_X.astype('float32') / 255\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "train_y = to_categorical(train_y)\n",
        "test_y = to_categorical(test_y)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xs5e8usAfS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "52766071-fa4a-46d2-c075-9ded062a28b8"
      },
      "source": [
        "history = model.fit(train_X, train_y, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 38s 783us/step - loss: 0.2413 - accuracy: 0.9269 - val_loss: 0.0753 - val_accuracy: 0.9770\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 37s 777us/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.0487 - val_accuracy: 0.9866\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 37s 778us/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 37s 773us/step - loss: 0.0415 - accuracy: 0.9873 - val_loss: 0.0408 - val_accuracy: 0.9884\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 37s 778us/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.0415 - val_accuracy: 0.9894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2aqfR8BqB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "647123bc-6f34-40e0-bc08-603a9ac78c23"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_X, test_y)\n",
        "print('Accuracy:', test_acc)\n",
        "print('Loss: ', test_loss)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 287us/step\n",
            "Accuracy: 0.9894000291824341\n",
            "Loss:  0.03335836813052483\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}