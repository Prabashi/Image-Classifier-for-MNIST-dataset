{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2O2HoIY2W1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBlDoHBe3pPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06556f4d-a81c-4f2b-d860-7d4a927e62e1"
      },
      "source": [
        "# load data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5EcVxYe4Uph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "# Set input shape in the first layer\n",
        "# First convolutional layer with filter size (3,3) and 32 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer with filter size (3,3) and 64 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "#  Flatten to provide features to the classifier\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layer to interpret the features with 64 nodes\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# To handle overfitting\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output layer. Has 10 nodes for 0-9 outputs. Use a softmax activation to find probabilities and assign classes\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZuoQ805SpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt = SGD(lr=0.01, momentum=0.9) # Stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9\n",
        "# opt = 'adam'\n",
        "opt = 'rmsprop'\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgwJ3mH9LVNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add noise to the dataset\n",
        "noise_factor = 0.25\n",
        "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)\n",
        "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape)\n",
        "\n",
        "train_X_noisy = np.clip(train_X_noisy, 0., 1.)\n",
        "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj3qa5U2_y1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing of the images\n",
        "# Reshape dataset to have 4D vector with the number of channels of the input image as 1 (since image is grayscale)\n",
        "train_X_noisy = train_X_noisy.reshape((60000, 28, 28, 1))\n",
        "test_X_noisy = test_X_noisy.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize by rescaling pixel values from range [0, 255] to [0, 1] by 1st converting the value to float and then by dividing from max value\n",
        "train_X_noisy= train_X_noisy.astype('float32') / 255\n",
        "test_X_noisy= test_X_noisy.astype('float32') / 255\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "train_y = to_categorical(train_y)\n",
        "test_y = to_categorical(test_y)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xs5e8usAfS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "84d1426b-63ee-4b06-f37d-20280643c413"
      },
      "source": [
        "history = model.fit(train_X_noisy, train_y, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3030 - accuracy: 0.1093 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2aqfR8BqB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3b63cd10-8ffd-4b1a-fab6-c853e5024e59"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_X_noisy, test_y)\n",
        "print('Accuracy:', test_acc)\n",
        "print('Loss: ', test_loss)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1135\n",
            "Accuracy: 0.11349999904632568\n",
            "Loss:  2.3010382652282715\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}