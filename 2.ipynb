{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2O2HoIY2W1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBlDoHBe3pPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02ef7781-8634-4c8f-93e1-c9b4ca335489"
      },
      "source": [
        "# load data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5EcVxYe4Uph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "# Set input shape in the first layer\n",
        "# First convolutional layer with filter size (3,3) and 32 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer with filter size (3,3) and 64 filters followed by a max pooling layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "#  Flatten to provide features to the classifier\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layer to interpret the features with 64 nodes\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# To handle overfitting\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "# Output layer. Has 10 nodes for 0-9 outputs. Use a softmax activation to find probabilities and assign classes\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZuoQ805SpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt = SGD(lr=0.01, momentum=0.9) # Stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9\n",
        "# opt = 'adam'\n",
        "opt = 'rmsprop'\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-hL87eRhgUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing of the images\n",
        "# Reshape dataset to have 4D vector with the number of channels of the input image as 1 (since image is grayscale)\n",
        "train_X = train_X.reshape((60000, 28, 28, 1))\n",
        "test_X = test_X.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize by rescaling pixel values from range [0, 255] to [0, 1] by 1st converting the value to float and then by dividing from max value\n",
        "train_X= train_X.astype('float32') / 255\n",
        "test_X= test_X.astype('float32') / 255\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "train_y = to_categorical(train_y)\n",
        "test_y = to_categorical(test_y)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgwJ3mH9LVNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add noise to the dataset\n",
        "noise_factor = 0.25\n",
        "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)\n",
        "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape)\n",
        "\n",
        "train_X_noisy = np.clip(train_X_noisy, 0., 1.)\n",
        "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xs5e8usAfS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "321e8dc5-697f-4f79-f829-91d316e6c030"
      },
      "source": [
        "history = model.fit(train_X_noisy, train_y, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.1103 - accuracy: 0.9668 - val_loss: 0.0917 - val_accuracy: 0.9727\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.0813 - accuracy: 0.9754 - val_loss: 0.0674 - val_accuracy: 0.9802\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.0593 - val_accuracy: 0.9834\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9833\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 37s 49ms/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0563 - val_accuracy: 0.9850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2aqfR8BqB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a1caace4-fe4d-46a4-de4a-406e3f86adae"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_X_noisy, test_y)\n",
        "print('Accuracy:', test_acc)\n",
        "print('Loss: ', test_loss)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0500 - accuracy: 0.9842\n",
            "Accuracy: 0.9842000007629395\n",
            "Loss:  0.05002663657069206\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}